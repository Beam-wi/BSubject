梯度消失存在两个地方：

（1）损失函数对权重参数w求导，这是误差反向传播的第一步，MSE（均方误差）的损失函数在这一步就会带来梯度消失问题，使用交叉熵损失可以避免这里的梯度消失；

（2）误差反向传播时的链式求导也会使得梯度消失，交叉熵损失不能解决链式求导带来的梯度消失，此时可以改善梯度消失的方法有：
	ReLU等激活函数；(增加非线性因子，让函数变得更复杂。比如指数函数随着指数增加倒数阶层也会随着增加)
	输入归一化、
	每层归一化(BN)，(此处我的理解是避免输入值异常，让最开始的输入及每层的输入都限制在一个可控的范围内，如果输入值非常小，在链式求导中被乘起来，梯度也是会趋于0的)；
	ResNet结构。