网页：https://blog.csdn.net/weixin_46142822/article/details/123958529

提出原因：
    提出anchorfree，针对anchorbase的缺点。
    1. boxes数据量和宽高比敏感问题          检测性能对 anchor boxes的数量和宽高比(aspect ratio)敏感；
    2. 小目标检测困难                      由于anchor boxes 的宽高比是固定的，难以处理尺度差异大的目标，尤其是小目标检测困难；
    3. 正负样本不均衡                      为了提高recall，anchor-based detector需要在输入图片上设置密集的anchor boxes，其中大部的anchor boxes是负样本，造成正负样本不平衡问题；
    4. IOU计算量大                         anchor boxes涉及例如IOU的大量计算；
    5. 违背了FCN一次计算的原则              一些FCN-based 检测框架如 DenseBox使用图像金字塔，对图片进行裁剪和缩放，以处理不同尺度的bbox，违背了FCN一次计算的原则。

结构：
    1. 前期与retinanet一致都backbone出来后接FPN，只是fcos用的 anchor-free, 关键点检测
    2. 学习的是分类 加上 中心点 和 中心点(x, y)到四个边的距离(l*, t*, r*, b*)，另外为了让学习后的中心点在正中间加了个centerness 横向最小/横向最大*纵向最小/纵向最大取更号



    该网络对小目标效果好

网络层输出：
    输入端           输入端表示输入的图片。该网络的输入图像大小为 W WW 和 H HH 。
    基准网络         基准网络用来提取图片特征。论文使用FPN网络，对每个像素点进行多尺度预测。
    Head输出端       Head用来完成目标检测结果的输出。输出head有5个，这5个head是共享权重的，每个head有三个分支，分别为：
                    目标类别classification(H×W×C)，中心度centerness(H×W×1)，和目标尺寸 Regerssion(H×W×4)。

    说明：最后输出的5个H*W的 “网格每个点” 就是目标对应的类别中心度和目标尺寸。


算法中名称解释：
    中心度         centerness* = 更号(min(l*, r*)/max(l*, r*) * min(t*, b*)/max(t*, b*))
                   即：对 横向最小/横向最大*纵向最小/纵向最大 取更号，取值范围为 0 ≤ centerness∗ ≤ 1，越往目标中心，中心度值越大

    中心度使用方法：
        在训练阶段：使用BCE loss，加入到代价函数中一起训练网络；
        在测试阶段：对预测的bbox进行打分：score_{final}=score_{classification } * centernessscore ，所低质量的bbox最后会通过NMS过滤掉。



由于FCOS使用的是FPN网络，进行多尺度预测规则：
    1. 每个特征层处理的正负样本是不同的，比如P3层用于预测小目标 (size范围[0, 64]) ，
       P4层用于预测较大目标 (size范围 [64, 128] )，每个特征层只负责回归满足如下条件的目标：

            m_i−1 ≤ max(l*, r*, t* ,b*) < m_i

        式中： m_i表示特征层i 需要回归某个目标的最大距离，论文中的设置：m_2, m_3, m_4, m_5, m_6, m_7
        取值分别为 0, 64, 128, 256, 512, 和 ∞。

    2. 每个 head 处理不同的特征尺度，所以 head 最后输出时进行的指数运算不是常规的exp(x)，而是 exp(s_i*x)，其中s_i是可学习的缩放因子。


loss设计
    FCOS 使用的代函数如下：

    式中：L_{cls}采用 focal loss；L_{reg}采用 IOU loss；N_{pos}是正样本数量；λ 为L_{reg}的平衡权重。

