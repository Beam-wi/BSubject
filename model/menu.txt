1. AUC/ROC曲线意义
2. AUC是什么？怎么计算？


3. 样本不平衡处理方法有哪些
4. 正样本特别稀疏该怎么处理？
5. 数据增广有哪些方法？
6. 如何进行特征选择？
7. 如何解决对过曝的图像进行目标检测？
8. 介绍形态学图像处理方法
9. 怎么处理长尾问题？从样本，模型的角度来看
10. 训练时出现不收敛的情况怎么办，为什么会出现不收敛
11. 介绍直方图均衡化
12. 积分图均值滤波如何实现
13. CV跨域问题该如何解决？


14. 分类问题为什么常用交叉熵loss？
15. 分类任务常用的目标函数
16. CRF的损失函数长啥样
17. 介绍Focal Loss及相关变体
18. Focal loss对数据不均衡缓解的原理



19. 卷积网络结构中的各个层原理
20. 介绍目标检测全部流程（输入到输出）
21. CNN中可以不用池化么？为什么？
22. ReLU和ReLU6的区别
23. 感受野如何计算？
24. 介绍BN和LN的区别
25. 介绍可变形卷积
26. 小卷积核和大卷积核的应用场景
27. PyTorch初始化需要注意什么？

28. Yolov4相对Yolov3的改进
29. 介绍YOLOv4和YOLOv5
30. 详细介绍RPN网络
31. RPN是干什么的？
32. Faster R-CNN有哪些不足？如何改进？
33. U-Net为什么在医学图像分割表现这么好
34. 怎么从Anchor变成具体坐标的
35. Transformer最核心的知识点
36. 介绍Transformer公式
37. Transformer 多头的作用？
38. ViT是怎么把Transformer应用到CV上的？
39. 介绍常用的移动端/轻量化模型
40. ImageNet top-1提升技巧有哪些？
41. 有哪些代表性的Attention？
42. 用PyTorch实现一下mlp网络结构
43. 介绍DeepLabV3的ASPP模块
44. 介绍知识蒸馏原理
45. 介绍anchor-free是什么？有哪些常见算法
46. TensorRT加速原理
47. 分类和聚类的区别与联系



48. 介绍HMM
49. HMM和CRF的区别
50. 手推 LR
51. LR与SVM的异同
52. SVM现场推导
53. LR逻辑回归为什么对特征进行离散化？
54. Bagging和Boosting的区别
55. 介绍XGBoost原理
56. XGBoost为什么要泰勒展开？
57. 介绍GBDT算法的原理与实现
58. GBDT和XGBoost的区别
59. XGboost是怎么做特征筛选的？
60. K-means与DBSCAN对比
61. KNN 和 K-means介绍一下
62. PCA属于有监督还是无监督？
63. CTR预估为什么是个分类而不是回归问题？
64. 介绍SVM、逻辑回归和决策树
65. 介绍一下SVM、逻辑回归和决策树
67. GAN训练时怎么解决训练坍塌问题？
68. DQN是On-policy还是off-plicy？


- 如果要学习一个新的领域，你会怎么开始入手？