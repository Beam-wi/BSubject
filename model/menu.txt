1. 介绍HMM
5. HMM和CRF的区别
4. AUC/ROC曲线意义
- AUC是什么？怎么计算？


9. 样本不平衡处理方法有哪些
- 正样本特别稀疏该怎么处理？
- 数据增广有哪些方法？
- 如何进行特征选择？
- 如何解决对过曝的图像进行目标检测？
- 介绍形态学图像处理方法
- 怎么处理长尾问题？从样本，模型的角度来看
- 训练时出现不收敛的情况怎么办，为什么会出现不收敛
- 介绍直方图均衡化
7. 积分图均值滤波如何实现
- CV跨域问题该如何解决？


- 分类问题为什么常用交叉熵loss？
- 分类任务常用的目标函数
6. CRF的损失函数长啥样
10. 介绍Focal Loss及相关变体
11. Focal loss对数据不均衡缓解的原理



16. 卷积网络结构中的各个层原理
- 介绍目标检测全部流程（输入到输出）
- CNN中可以不用池化么？为什么？
- ReLU和ReLU6的区别
- 感受野如何计算？
- 介绍BN和LN的区别
- 介绍可变形卷积
- 小卷积核和大卷积核的应用场景
- PyTorch初始化需要注意什么？

14. Yolov4相对Yolov3的改进
- 介绍YOLOv4和YOLOv5
- 详细介绍RPN网络
- RPN是干什么的？
- Faster R-CNN有哪些不足？如何改进？
12. U-Net为什么在医学图像分割表现这么好
13. 怎么从Anchor变成具体坐标的
- Transformer最核心的知识点
- 介绍Transformer公式
- Transformer 多头的作用？
- ViT是怎么把Transformer应用到CV上的？
- 介绍常用的移动端/轻量化模型
- ImageNet top-1提升技巧有哪些？
- 有哪些代表性的Attention？
- 用PyTorch实现一下mlp网络结构
- 介绍DeepLabV3的ASPP模块
- 介绍知识蒸馏原理
15. 介绍anchor-free是什么？有哪些常见算法
- TensorRT加速原理
8. 分类和聚类的区别与联系




- 手推 LR
- LR与SVM的异同
3. SVM现场推导
- LR逻辑回归为什么对特征进行离散化？
- Bagging和Boosting的区别
2. 介绍XGBoost原理
- XGBoost为什么要泰勒展开？
- 介绍GBDT算法的原理与实现
- GBDT和XGBoost的区别
- XGboost是怎么做特征筛选的？
- K-means与DBSCAN对比
- KNN 和 K-means介绍一下
- PCA属于有监督还是无监督？
- CTR预估为什么是个分类而不是回归问题？
- 介绍SVM、逻辑回归和决策树
- 介绍一下SVM、逻辑回归和决策树
- GAN训练时怎么解决训练坍塌问题？
- DQN是On-policy还是off-plicy？


- 如果要学习一个新的领域，你会怎么开始入手？