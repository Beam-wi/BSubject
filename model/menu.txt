# 评价指标
1. 介绍HMM
2. HMM和CRF的区别
3. AUC/ROC曲线意义
4. AUC是什么？怎么计算？


# 数据
5. 样本不平衡处理方法有哪些
6. 正样本特别稀疏该怎么处理？
7. 数据增广有哪些方法？
8. 如何进行特征选择？
9. 如何解决对过曝的图像进行目标检测？
10. 介绍形态学图像处理方法
11. 怎么处理长尾问题？从样本，模型的角度来看
12. 训练时出现不收敛的情况怎么办，为什么会出现不收敛
13. 介绍直方图均衡化
14. 积分图均值滤波如何实现
15. CV跨域问题该如何解决？


# 损失
16. 分类问题为什么常用交叉熵loss？
17. 分类任务常用的目标函数
18. CRF的损失函数长啥样
19. 介绍Focal Loss及相关变体
20. Focal loss对数据不均衡缓解的原理


# 网络
21. 卷积网络结构中的各个层原理
22. 介绍目标检测全部流程（输入到输出）
23. CNN中可以不用池化么？为什么？
24. ReLU和ReLU6的区别
25. 感受野如何计算？
26. 介绍BN和LN的区别
27. 介绍可变形卷积
28. 小卷积核和大卷积核的应用场景
29. PyTorch初始化需要注意什么？


# 模型
30. Yolov4相对Yolov3的改进
31. 介绍YOLOv4和YOLOv5
32. 详细介绍RPN网络
33. RPN是干什么的？
34. Faster R-CNN有哪些不足？如何改进？
35. U-Net为什么在医学图像分割表现这么好
36. 怎么从Anchor变成具体坐标的
37. Transformer最核心的知识点
38. 介绍Transformer公式
39. Transformer 多头的作用？
40. ViT是怎么把Transformer应用到CV上的？
41. 介绍常用的移动端/轻量化模型
42. ImageNet top-1提升技巧有哪些？
43. 有哪些代表性的Attention？
44. 用PyTorch实现一下mlp网络结构
45. 介绍DeepLabV3的ASPP模块
46. 介绍知识蒸馏原理
47. 介绍anchor-free是什么？有哪些常见算法
48. TensorRT加速原理
49. 分类和聚类的区别与联系


# 机器学习
50. 手推 LR
51. LR与SVM的异同
52. SVM现场推导
53. LR逻辑回归为什么对特征进行离散化？
54. Bagging和Boosting的区别
55. 介绍XGBoost原理
56. XGBoost为什么要泰勒展开？
57. 介绍GBDT算法的原理与实现
58. GBDT和XGBoost的区别
59. XGboost是怎么做特征筛选的？
60. K-means与DBSCAN对比
61. KNN 和 K-means介绍一下
62. PCA属于有监督还是无监督？
63. CTR预估为什么是个分类而不是回归问题？
64. 介绍SVM、逻辑回归和决策树
65. 介绍一下SVM、逻辑回归和决策树
66. GAN训练时怎么解决训练坍塌问题？
67. DQN是On-policy还是off-plicy？


- 如果要学习一个新的领域，你会怎么开始入手？