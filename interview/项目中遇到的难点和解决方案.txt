1. 小目标的AP一般比中目标和大目标低很多。
    Coco数据集中也包含大量的小目标，但比较麻烦的是小目标的分布并不均匀。Coco数据集中小目标占比达到41.4%，数量比中目标和大目标都要多。
    但在所有的训练集图片中，只有52.3%的图片有小目标，而中目标和大目标的分布相对来说更加均匀一些。针对这种状况，
    Yolov4的作者采用了Mosaic数据增强的方式。

    Mosaic数据增强 主要有2个优点：
        a. 丰富数据集：随机使用4张图片，随机缩放，再随机分布进行拼接，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。
        b. batch不需要很大：Mosaic增强训练时，可以直接计算4张图片的数据，使得Mini-batch大小并不需要很大，一个GPU就可以达到比较好的效果。


2.


一、之前做过哪些项目，项目中担任的职务

二、项目中遇到的困难，怎么解决的
    1. 数据
        a. 初期：
            数据标注规则、数据标注质量、数据量、数据多样性合理分布等。
        b. 规划阶段
            能否从用户实际场景采集数据
            需要采集多大范围的数据
            需要多少有效数据
        c. 使用GAN的方法来扩充数据等等手段。
        d. 有效数据（现场可能出现得各种特殊情况）

    2. trick
        a. 模型本身
            1.尝试各种开源小模型，找到相对比较高的合适自己计算量的模型
            2.尝试多种主干网络
            3.减小通道数，block数量
            4.分析多尺度层，哪些是针对自己任务无效的层
            5.适当修改头
            通过不断实验，加数据保证精度下降不太多
            数据质量本身
            数据质量越高，标注质量越高，标注规则模糊性越小，模型可以做的越小

        b. pipeline
            1. 共享权重，多任务学习
            2. 不同任务拆成不同的网络


    3. 中后期
        重点转移到模型压缩上，一是满足项目的要求，二满足成本的要求
        重点转换到数据链路的精细化管理，建设数据平台能力


三、yolov3和yolov4以及yolov5的特点差异，是怎么评估最终选择yolov3的
    a. 正负样本定义
        1. yolov3/yolov4的正负样本定义：
            1.保证每个GT有一个唯一的anchor进行对应，匹配规则为IOU最大（没有阈值），选取出来的即为正样本；
            2.其余为负样本，但是得从其中选取IOU>0.5（设定阈值）的作为忽略样本，因为负样本中仍有大量IOU与GT很大但是质量不是很高，作为负样本也不合适；
            3.正anchor用于分类和回归的学习，正负anchor用于置信度confidence的学习，忽略样本不考虑。

            yolov3/yolov4的正负样本定义小细节：
                GT需要利用max iou原则分配到不同的预测层yolo-head上去，然后在每个层上单独计算正负样本和忽略样本。
                不存在某个GT会分配到多个层进行预测的可能性，而是一定是某一层负责的。

        2. yolov5的正负样本定义：
            yolov5相比上一代增加了正样本anchor数目，这样可以显著加速收敛。

            计算流程：
                1.将每个boundingbox重复3份（每层有3个anchor），方便和每个位置的3个anchor单独匹配；
                2.没有采用IOU最大的匹配方法，而是通过计算该boundingbox和当前层的anchor的宽高比，如果最大比例大于4（设定阈值），则比例过大，则说明匹配度不高，将该bbox过滤，在当前层认为是背景；
                3.对于剩下的bbox，计算其落在哪个网格内，同时利用四舍五入规则，找出最近的两个网格，将这三个网格都认为是负责预测该bbox的，可以发现粗略估计正样本数相比前yolo系列，至少增加了三倍。

            yolov5的正负样本定义小细节：
                (1) 不同于yolov3和v4，其gt bbox可以跨层预测即有些bbox在多个预测层都算正样本
                (2) 不同于yolov3和v4，其gt bbox的匹配数范围从3-9个,明显增加了很多正样本(3是因为多引入了两个邻居)
                (3) 不同于yolov3和v4，有些gt bbox由于和anchor匹配度不高，而变成背景

    b. iou-loss
        yolov5: GiouLoss




项目中遇到得问题：
    一、 模型方面
        1. 配置标准件
            a. 通常检测需要自动判断测试结果是否合格，背景误报会对结果判断有影响。
            b. 通过标准间与检测数据的点位匹配判断目标是否检测到
            c. 具体的方法是单目与双目识别包括平面使用图像坐标匹配，立体的使用世界坐标匹配
            d. 还有一种方式是在工件的某些特定位置标注一些点位，通过点位顺序去与标准间进行匹配，
                这里我们的处理方式是将感受野大的特征层指定学习该类点位，我们的目的是工件结构信息。

        2. 模型模块化
            a. 比如目标检测中检测与分类学习程度通常会有差异，有时检测效果要远优于分类效果。
            b. 所以我们的思路是将检测任务与分类任务独立化分开进行。将原本两个互相关联的问题转化为两个独立的问题。
            c. 比如如果检测效果极好，那么我们只需要单独优化分类即可。另外在模型更新时也降低训练成本。

        4. 类别信息按照标准间配置传入
            a. 比如我们有多个工件时，每个工件类别不一样，但模型是同一个，在每次检测时只传入该工件下的类别，
            b. 在分类时我们只取给定类别下的softmax后argmax前的信息，减少相似类和无关类的影响提高分类得分。

        3. 按照类别独立设置检测和分类阈值
            a. 比如不同类别之间最优AP下检测和分类阈值往往不一样。同一套阈值可能会导致各类别AP不全为最优。

        5. 根据检测点特性制定不同的模型
            a. 静态点，比如螺丝、开关按钮这些形状大小位置相对工件来说不变化或微变化的我们会采用anchor模型，一般有yolov3, fousnet,
                当然我们的yolov3是经过我们改进后的。
            b. 动态点，比如头发丝，异物，杂质这些形状大小位置相对不确定性的目标我们会采用anchor free模型，一般有centnet ATSS



    二、 数据训练方面
        1. 小数据集防止过拟合
            a. 以目标点为标准按照检测点的比例选取，然后选取周边随机大小区域resize到固定尺寸（我们一般设为1024*1024）
            b. 输入到模型，通过调整随机尺寸相对输入尺寸的大小从而达到多尺度的目的，前后加上常规的旋转仿射颜色变换数据增强，防止过拟合。

        2.





细述工作内容
    1. tensorrt

    2. tritonserver

    3. 推断模块

    4. 摄像头模块，海康威视 映美精

    5. 自动训练

    6. 自动检测发布（正在开发中）



    1. 手动贴得长条形黑色物体检测，标注不容易，（背景和目标区分度小）检测容易漏检？